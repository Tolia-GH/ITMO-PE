## [MainPage](../../index.md)/[Computer Vision](../README.md)/[Lecture](../Lecture.md)/5-2 RAW

语音识别：Youtube 转文本
断句与标点：
翻译：

вообще говоря если рассматривать сегментирование изображений как кластеризацию пикселов то для решения задачи сегментирования нам подойдут хорошо известный классический алгоритмы кластеризации поэтому мы не можем пройти мимо cummins алгоритм является неконтролируемым алгоритмом используется для отделения сегментов друг от друга или от фона в частности он группирует разделяет данные на к кластеров или части на основе к центроидом алгоритм используется когда есть не размеченные данные то есть данные без определенных категорий и групп то есть данный алгоритм не используют никакой априорной информации помимо количество crow астров цель состоит в том чтобы найти определенные группы на основе некоторого сходства данных с количеством групп которая обозначена к целью кластеризации cummins является минимизация суммы квадратов расстояний между всеми точками и центром кластера шаги в алгоритме cummins сначала выбирается количество кластеров то есть к далее выбирается случайным образом к точек которые являются центроида me они не обязательно принадлежат набору данных далее происходит назначение каждой точке из классифицировала множество ближайшему центроида таким образом формируется к кластеров далее вычисляется новый центроид для каждого кластера после этого каждая . из класс 3 зa имаго множество назначается новому ближайшему центроида если точки были переназначены центроида который и так был за ними закреплен или же достигнуто другое условие останова то алгоритм завершается в противном случае происходит итеративно и пересчет центроида фэс перри назначением точек возникает вопрос как выбрать оптимальное значение k для определенного класса алгоритмов кластеризации в частности для cummins есть параметр обычно называемый к которая определяет количество кластеров для обнаружения ну собственно говоря кад в нашем случае если говорить именно о cummins то правильный выбор к часто неоднозначен с интерпретациями которые зависят от формы масштаба распределение точек в наборе данных и желаемого разрешения кластеризации для пользователя кроме того увеличение к без штрафа всегда будет уменьшать количество ошибок в результирующей кластеризации до крайнего случая 0 ошибки если каждая точка данных рассматривается как свой собственный кластер то есть когда k равно количеству точек данных тогда интуитивно оптимальный выбор к обеспечит баланс между максимальным сжатием данных с использованием одного кластера и максимальной точностью назначая каждую точку данных своему кластеру если подходящее значение к не очевидно из предыдущего значения свойств набора данных его нужно каким-то образом выбрать есть несколько категорий методов для принятия этого решения метод локтя один из таких основная идея методов разделения таких как авторизация к средних состоит в том чтобы определить кластеры таким образом чтобы общая вариация внутри кластера или другими словами общая сумма квадрата внутри кластера было минимизирована таким образом достигается компактность кластеризации и уменьшается то есть производится оптимизации данного параметра металл акте преследует именно такую цель рассмотрим подробнее шаги по выбору оптимального количества кластеров вычисляется кластеризация методом cummins для различных значений k варьируя k от 1 до 10 далее для каждого к вычисляется общая сумма квадрата внутри кластера далее строится кривая зависимости общей суммы квадрата от количество кластеров расположение изгиба на данной кривой обычно рассматривается как показатель соответствующего количество кластеров но есть подвох несмотря на все преимущества cummins иногда терпят неудачу из-за случайного выбора центроида фф и такая ситуация называется случайной ловушка инициализация чтобы решить эту проблему у нас есть процедура инициализации для cummins который называется cummins + + она предлагает выбор начальной инициализации для cummins каминс плюс плюс выбирается . случайным образом и это первый центроид затем выбирается следующая точка на основе вероятностей который зависит от расстояния до первой точке чем дальше друг от друга . тем более она вероятно затем получается 2 центроида далее процесс повторяется с учетом того что вероятность каждой точке основана на расстояние до ближайшего центроида к этой точке настоящее время это приводит к накладным расходам при инициализация алгоритма но снижает вероятность неправильной инициализации приводящий к плохому результату кластеризации главное отличие алгоритмов а с дейта и cummins заключается в том что на стадии инициализация алгоритма aes aldo это происходит распределение пикселов в то время как для алгоритма cummins происходит распределение значений математических ожиданий поэтому ниже будет рассмотрен результат применения алгоритма aes аудита данный алгоритм использует минимальное спектральное расстояние для определения соответствующего кластера для каждого пикселя процесс начинается с назначение случайного или приближенного среднего значения кластера и повторяется до тех пор пока это значение не достигнет величины среднего для каждого кластера исходных данных начальные среднее значение класс трав распределяются равномерно вдоль центрального вектора спектрального пространство в течение первой итерации кластеризации пространство равномерно разбивается на области центром каждый из которых являются средние значения кластеров пик сила анализируется с левого верхнего угла изображения к правым нижним вычисляется спектральное расстояние между пикселами и средним значением кластера пикселы назначаются в тот класс стр где расстояния минимально после итерация рассчитывают реальные средние значения спектральных признаков полученным кластерам так как их средние значения меняются в зависимости от преобладающих йер костей попавших в них пикселов затем выполняется вторая итерация в процессе которой повторяют кастомизацию с новыми средними значениями и расчитывают границы кластеров после этого определяют новые средние значения и выполняют новую трассу в процессе второй итерации снова определяются минимальное спектральное расстояние между точками и новыми средними значениями кластеров по окончанию которой пикси вы будут перераспределены такие пересчет и повторяются до тех пор пока все пикселя с заданной вероятностью или порогом сходимости не попадут в какой-либо кластер отметим что возможна ситуация когда распределение значения яркости на снимке не фиксируются в каком-либо класс 3 поэтому ограничивающим фактором здесь будет являться заданное число итераций перейдем к очередному алгоритму кластеризация for all от слова сочетания формальный элемент это метод customization основанный на идее объединение в один кластер объектах объектов в областях их наибольшего сгущения в данном случае цель квас 3 зации стандартная разбить выборку на такое заранее неизвестное число кластеров чтобы сумма расстояние от объектов кластеров до центров кластеров было минимальный по всем кластерам таким образом задача выглядит как выделение группы максимально близких друг другу объектов которые всю гипотезы схожести и будут образовывать наши кластеры таким образом задача состоит минимизации функционала качество который представлен на слайде первое суммирование ведется по всем кластерам выборки второе по всем объектам x принадлежащим текущему кластеру кей джи than a wg-3 это центр текущего кластера соответственно при этом ро от x и y это расстояние между двумя объект отметим необходимые условия для использования алгоритмов во-первых выполнение гипотеза компактности предполагающий что близкие друг другу объекты с большой вероятностью принадлежат к одному кластеру во вторых наличие линейного или метрического пространства куста рисуем их объектов итак на вход алгоритму подаётся просто ризу и мая выборка которая может быть задано при знаковыми описание объектов это как мы уже говорили линейное пространство либо матрица парных расстояний между объектами при этом в реальных задач на больших данных зачастую хранение всех данных невозможной и бессмыслена му необходимые данные собираются в процессе кластеризации параметр r радиус поиска вокальных сгущение его можно задавать как и запорных соображений то есть знания диаметре кластеров так и настраивать скользящим контролем также в модификации данного подхода возможно введение параметра к то есть количество кластеров ну и на выходе мы получаем авторизацию на заранее неизвестное число кластеров на выходе алгоритма в классической его реализации так подробнее рассмотрим принцип работы на каждом шаге случайным образом выбираем объект из выборки раздуваем вокруг него сферу радиус r внутри этой сферы выбираем центр тяжести делом его центром новой сферы то есть мы на каждом шаге двигаем сферу в сторону локального сгущения объектов выборки то есть стараемся захватить как можно больше объектов выборки сферы фиксированного радиуса после того как центр сферы стабилизируется все объекты внутри сферы с этим центром мы помечаем как кластере за ванные и выкидываем их из выборки этот процесс мы повторяем до тех пор пока вся выборка не будет cost аризона рассмотрим алгоритм по шагам несколько продублировал вышесказанное на первом шаге мы случайно выбираем текущие объект из выборки на втором помечаем объекты выборки находящиеся на расстоянии меньше чем r от текущего на третьем вычисляемых центр тяжести и помечаем этот центр как новый текущий объект на четвертом повторяем 2 и 3 шаги пока новый текущий объект не совпадет с прежним помечаем объекты внутри сферы радиус r вокруг текущего объекта как холст рисованные и выкидываем и их из выборки на шестом повторяем шаги с 1 по 5 пока не будет кустари зова на вся выборка рассмотрим некоторые эвристики выбрать центры тяжести во-первых в линейном пространстве он можно использовать центр масс метрическом пространстве объект сумма расстояний до которого минимально среди всех объектов внутри сферы далее можно использовать объект который внутри сферы радиус r содержит максимальное количество других объектов из всей выборки но надо понимать что априорное вычисление такого объекта требует отдельных временных ресурсов и не только временных ну и в конце концов можно использовать объект который внутри сферы маленького радиуса содержит максимальное количество объектов ну и некоторые общие детали в по поводу данного алгоритма значит для него доказано сходимость за конечное число шагов в линейном пространстве центром тяжести может выступать произвольная точка пространства а в метрическом только объект выборки очевидным фактом является что чем меньше радиус сферы р тем больше кластеров на выходе отдает алгоритм в линейном пространстве поиск центр происходит за линейное время а в метрическом за квадратичное наилучших результатов алгоритм достигает на выборках с хорошим выполнением условий компактности при повторении интераций возможно уменьшение параметра r для скорейшей сходимости кластеризация сильно зависит от начального приближения то есть выбор объекта на первом шаге и в конце концов рекомендуется повторная прогонка алгоритма для исключения ситуация вид плохой кластеризации по причине и удачного выбора начальных объектов преимуществами данного алгоритма является точность минимизации функционала качество разумеется при удачном подборе параметра р наглядность визуализации кластеризации сходимости алгоритма возможности операции на центрами кластеров они известны в процессе работы алгоритма также из преимуществ можно отметить возможность подсчету промежуточных функционалов качество например длины цепочки локальных сгущению к тому же алгоритм предоставляет возможность проверки гипотез схожести и компактности в процессе работы алгоритма из недостатков можно отметить относительно низкую производительность так как производится пересчет поиска центра при добавлении одного объекта внутрь сфера вторым недостатком является плохая применимость алгоритма при плохой раздели масти выборки на кластеры еще одним недостатком является неустойчивость алгоритма в смысле зависимости от выбора начального объекта также существенным недостатком является необходимость априорных знаний о ширине или диаметре кластеров как уже было сказано ранее при рассмотрении каждого пиксела изображение в качестве элемента некоторого пространства например пространство совмещающего в своих компонентах цветовые и пространственные составляющие пикселов изображения мы можем использовать обычный алгоритм и кластеризации для разделения пикселов на кластеры таким образом выполняя сегментирование изображений с помощью классических алгоритмов кластеризации продолжим изучать подобное решение следующий алгоритм к авторизации не требует априорного задания числа костров он носит название деби scan если перевести полное название алгоритма на русский язык то получится что-то вроде основанная на плотность и пространственная кастомизация для приложений с шумами данная алгоритм кластеризации основан на плотности если дан набор точек в некотором пространстве алгоритм группируют вместе точки которые тесно расположены то есть точки со многими близкими соседями помечая как вы барсы точки которые находится одиноко в областях с малой плотностью то есть ближайшие соседи которых лежат далеко baby скан является одним из наиболее часто используемых алгоритмов кластеризации и наиболее часто упоминается в научной литературе в 2014 году алгоритм получил премию проверено временем премия дает с алгоритмом которые получили существенное внимание в теории и практике но ведущий конференция по интеллектуальному анализу данных теги div рассмотрим стадию подготовки перед запуском основной части алгоритма на вход подается набор точек в некотором пространстве требующий кластеризации для выполнения кластеризации деби скан деле точки на основные достижимые по плотности и выпадающий следующим образом . p является основной точкой если по меньшей мере определенное заранее количество точек находится на расстоянии не превосходящим определенное заранее число эпсилон которая является максимальным радиусом соседство от п до неё включая саму точку p говорят что эти точки достижим прямо из п точка q primo достижимой с.п. если . он находится на расстоянии не больше мы обсе он от точки p & p должно быть основной точкой . достижимо из п если имеется путь из последовательности точек где каждая точка достижимо прямо из предыдущей причем начальной точкой в данной последовательности является п.а. конечный наша целевая . все точки недостижимые из основных точек считаются выбросами следует сделать некоторую оговорку последовательность точек которую мы рассматривали при введении понятия достижимости связаны между собой имеется ввиду точки соседние в последовательности прямой достижимость you теперь если появляется основной точкой то она формирует кластер вместе со всеми точками основными или не основными достижимыми из точки p каждый кластер содержит по меньшей мере одну основную точку не основные точки могут быть частью кластера но они формируют его край поскольку не могут быть использованы для достижения других точек ежи масть не является симметричным отношением поскольку по определению никакая . не может быть достигнуто из не основной точки независимо от расстояния так что не основная точка может быть достижимой но ничто не может быть достигнуто из неё поэтому дальнейшее понятие связанности необходимо для формального определения области кластера найденной с помощью baby сканд две точки p и q связаны по плотности если имеется . о такая что паек у достижимы из о связанность по плотности является симметричным отношении таким образом кластер удовлетворяет двум свойствам все точки в кластере попарно связаны по плотности если . достижимо по плотности из какой-то точке кластера она также принадлежит кластеру теперь рассмотрим базовую часть оригинального алгоритма disk on требует задание двух параметров размер окрестности обсе он точнее радиус и минимальное число точек которые должны образовывать плотную область алгоритм начинается с произвольной точке которой еще не просматривалось выбирается и psion окрестность точки если она содержит достаточно много точек образуется кластер в противном случае . помечается как шум заметим что эта точка может быть позже найдено в psion окрестности другой точки и включена в какой-то класс стр если точка найдена как плотная . кластера и и обсе он окрестность также является частью этого кластера следовательно все точки найдены веб всего на окрестности этой точке добавляются кластеру этот процесс продолжается пока не будет найден связанный по плотности кластер затем выбирается обрабатывается новая не посещена я . что ведет к обнаружению следующего кластера или шума baby скан может быть использован с любой функции расстояния а также с функцией похожести или логическим условием сама функция расстояния может быть рассмотрена как дополнительный параметр если описать алгоритм сжато то можно ограничиться следующий формулировкой сначала находим точки в в psion окресности каждой точке и выделяем основные точки с более чем заданным числом соседей далее находим связанные компоненты основных точек на графе соседей игнорируя все не основные точки далее назначаем каждую не основную точку ближайшему кластеру если кластер является с соседним в терминах обсе он окресности в противном случае считаем точку шумом наивная реализация алгоритма требует запоминания соседей поэтому требует существенного количество памяти оригинальный алгоритм baby скан не требует этого за счет того что выполняет все шаги для одной точке за один раз и без контачит каждую точку исходного набора несколько раз зависимости о потребности во время своей работы например в качестве рассмотрения их как кандидатов в другие кластеры по опыту эксплуатации временная сложность в основном регулируется числом запросов debbie скан выполняет в точности один запрос для каждой точки и если используется индексная структура которая выполняет запрос соседство за время о большое от ул окон получаем полную среднюю временную сложность о большой от unlock н если параметры обсе он выбирается осмысленно то есть так что в среднем возвращается только о большое от локон точек без использования ускоряющий индексной структуры или на вырожденных данных например когда все точки находятся на расстоянии меньшим чем апсент худшем случае им времени работы остается о большой от n квадрат матрица расстояние размера n в квадрате минус n пополам может быть вычислено вы во избежание перри вычисления расстояний но это требует памяти о большое от n квадрат в то время как реализация деби скан без матрица расстояний требует лишь у большой aten памяти рассмотрим далее преимущество используемый не деби скан во-первых деби скан не требуют спецификации числа кластеров в данных априори в отличие от метода cummins например вторых деби скан может найти кластеры произвольной формы он может найти даже кластеры полностью окруженные но не связанные с другими кластерами благодаря параметру минимального количества точек в psion окресности уменьшается так называемый эффект одной связи когда осуществляется связь различных кастеров тонкой линии точек деби скан имеет понятия шума и устойчив к выбросам более того деби скан требует лишь двух параметров и большей частью не чувствителен к порядку точек в базе данных однако точки находящиеся на границе двух различных кластеров могут оказаться в другом кластере если изменить порядок точек она значение кластеров оставить единственным точностью до изоморфизма baby скан разработан для применения с базами данных что позволяет ускорить запросы в диапазоне значений например с помощью специфичных структур хранения и оптимизации поиска ближайших соседей ну и в завершении параметры минимального количества точек в окрестности и радиус окресности могут быть установлены экспертами в рассматриваемой области если данные хорошо понимаются то есть возможно привлечение domain специфик специалистов но наряду с достоинствами baby скан обладает рядом недостатков во-первых деби скан не полностью однозначен краевые точки могут быть достигнуты из более чем одного кластера и могут принадлежать любому из этих кластеров что зависит от порядка просмотра точек для большинства наборах данных эти ситуации возникают редко и имеют малое влияние на результат customization основные точки шум baby скан обрабатывает однозначно качество деби скан зависит от измерения расстояния используемого функции кластере зуи маму набору точек наиболее частой используемый метрика и расстояние является евклидова метрика особенно для кластеризации данной высокой размерности это метрика может оказаться почти бесполезны виду так называемого проклятия размерности что делает трудным делом нахождение подходящего значения в конце концов если данные масштаб не вполне хорошо понятно то выбор осмысленного порога расстояния то есть опциона может оказаться трудным