## [MainPage](../../index.md)/[Computer Vision](../README.md)/[Lecture](../Lecture.md)/RAW

语音识别：Youtube 转文本
断句与标点：chatGPT 4o
翻译：chatGPT

# Глубокие нейросетевые архитектуры для детектирования человеческих лиц <br>用于检测人脸的深度神经网络架构

Другим важным частным случаем детектирования объектов является детектирование лиц. В сегодняшней лекции мы уже рассмотрели алгоритм Виола и Джонса. Теперь сосредоточимся на подходах, основанных на глубоком обучении, для решения задачи детектирования человеческих лиц.  
另一个重要的特例是人脸检测。在今天的讲座中，我们已经讨论了Viola和Jones算法。现在，我们将集中精力研究基于深度学习的人脸检测方法。

Мультитаск-канвас нейронная сеть (Multitask-Cascaded Convolutional Neural Network, MTCNN) представляет собой каскад из трех нейросетей, которые предсказывают как охватывающий прямоугольник, так и набор из ключевых точек лица: уголки глаз, нос, рот и другие характерные точки на лице. Собственно говоря, поэтому данная архитектура и получила такое название. В основе её как релиз слайда лежит простой ансамбль из трех нейросетевых архитектур, которые по сути дела имеют одинаковые выходы, семантически одинаковые, но с дополнительной точностью и устойчивостью предсказаний, достигаемой с помощью избыточного количества предсказателей.  
多任务级联卷积神经网络（Multitask-Cascaded Convolutional Neural Network, MTCNN）由三个神经网络级联组成，能够预测包围框和一组人脸的关键点，如眼角、鼻子、嘴巴和其他特征点。正因如此，这种架构得名为多任务级联。在其实现中，MTCNN包含了三个神经网络架构的简单集合，这些架构本质上有相同的输出，语义上也是一致的，但通过大量预测器的冗余，提高了预测的准确性和稳定性。

Архитектура свёрточной нейронной сети RetinaNet состоит из четырёх основных частей, каждая из которых имеет своё назначение:  
RetinaNet的卷积神经网络架构由四个主要部分组成，每个部分都有其特定的功能：

1. **Backbone** представляет собой свёрточный кодировщик, который служит для извлечения признаков из поступающего на вход изображения. Данная часть архитектуры является вариативной, и в её основу могут входить различные классификационные сети, такие как ResNet, VGG и EfficientNet. Многие из них мы рассматривали в нашей лекции про классификацию изображений.  
   Backbone 是一个卷积编码器，用于从输入图像中提取特征。这部分架构是可变的，可以基于不同的分类网络，如ResNet、VGG和EfficientNet。我们在图像分类讲座中讨论了许多这些网络。

2. **Feature Pyramid Network (FPN)** свёрточная нейронная сеть построена в виде пирамиды и служит для объединения карт признаков нижних и верхних уровней сети. Первые имеют высокое разрешение, но низкую семантическую обобщающую способность, вторые наоборот.  
   特征金字塔网络（Feature Pyramid Network, FPN） 是一种卷积神经网络，构建成金字塔形状，用于结合网络中不同层次的特征图。底层特征图具有高分辨率但低语义抽象能力，而顶层特征图则相反。

3. **Classification Subnet** – подсеть, извлекающая из FPN информацию о классах объектов, решая задачу классификации.  
   分类子网（Classification Subnet） 从FPN中提取对象类别信息，解决分类问题。

4. **Regression Subnet** – подсеть, извлекающая из FPN информацию о координатах объектов на изображении, решая задачу регрессии.  
   回归子网（Regression Subnet） 从FPN中提取对象坐标信息，解决回归问题。

Рассмотрим подробнее перечисленные составляющие общей архитектуры.  
下面我们详细讨论这些组成部分的整体架构。

## Backbone

Часть архитектуры RetinaNet, которая принимает на вход изображение и выделяет важные признаки, является вариативной. Извлеченная из этой части информация будет обрабатываться на следующих этапах, поэтому важно выбрать подходящую backbone-сеть для лучших результатов. Недавние исследования по оптимизации свёрточных нейронных сетей позволили разработать классификационные модели, которые опередили все ранее разработанные архитектуры с лучшими показателями точности. Эти сети получили название EfficientNet. Они основаны на автоML-подобном подходе, и их крайне настоятельно рекомендуется использовать в качестве backbone.  
RetinaNet架构的这一部分负责接受输入图像并提取重要特征，这部分架构是可变的。从这一部分提取的信息将在后续阶段处理中，因此选择适当的backbone网络以获得最佳结果非常重要。最近关于优化卷积神经网络的研究开发了超越之前所有架构的分类模型，这些模型在准确性上表现出色。它们被称为EfficientNet，基于自动机器学习（AutoML）方法，强烈建议在backbone中使用它们。

## Устройство пирамиды признаков <br>特征金字塔网络（FPN）的结构

Feature Pyramid Network (FPN) состоит из трёх основных частей: восходящий путь (bottom-up pathway), нисходящий путь (top-down pathway) и боковые соединения (lateral connections).  
FPN由三个主要部分组成：上行路径（bottom-up pathway）、下行路径（top-down pathway）和侧向连接（lateral connections）。

1. **Восходящий путь** представляет собой иерархическую пирамиду, то есть последовательность свёрточных сетей с уменьшающейся размерностью. В нашем случае backbone сеть. Верхние слои свёрточных сетей имеют большее семантическое значение, но меньшее разрешение, а нижние наоборот.  
   上行路径 是一个层次化的金字塔，表示一系列卷积网络，其尺寸逐渐减小。在我们的例子中是backbone网络。上层卷积网络具有更高的语义意义但分辨率较低，而下层则相反。

2. **Нисходящий путь** также представляет собой пирамиду. Карты признаков верхнего слоя этой пирамиды имеют размер карт признаков верхнего слоя bottom-up пирамиды и увеличиваются вдвое методом ближайшего соседа по направлению вниз. Это проиллюстрировано на рисунке, представленном на слайде. Таким образом, в top-down сети каждая карта признаков вышележащего слоя увеличивается до размеров карты нижележащего.  
   下行路径 也是一个金字塔。这个金字塔的上层特征图尺寸与bottom-up金字塔的上层特征图相同，并通过最近邻方法向下放大一倍。在幻灯片上展示的图示说明了这一点。因此，在top-down网络中，每个上层特征图都会放大到下层特征图的尺寸。

3. **Боковые соединения** означают, что карты признаков соответствующих слоёв bottom-up и top-down пирамид поэлементно складываются, причём карты из bottom-up проходят свёртку "один на один". Этот процесс также схематично представлен на рисунке. Боковые соединения решают проблему затухания важных сигналов в процессе прохода по слоям, совмещая семантически важную информацию, полученную к концу первой пирамиды, и более детальную информацию, полученную в ней ранее.  
   侧向连接 意味着bottom-up和top-down金字塔相应层的特征图逐元素相加，且bottom-up的特征图经过"一对一"卷积。这一过程在幻灯片中也有示意图。侧向连接解决了信号在层间传递过程中的衰减问题，将第一金字塔末端获得的语义信息与之前获取的详细信息结合起来。

Далее каждый из полученных слоёв в top-down пирамиде обрабатываются двумя подсетями.  
接下来，top-down金字塔中每个获得的层都会经过两个子网的处理。

## Подсети классификации и регрессии <br>分类和回归子网

Третьей частью архитектуры RetinaNet являются две подсети: классификационная и регрессионная. Каждая из этих подсетей формирует на выходе ответ о классе объекта и его расположении на изображении. Рассмотрим принцип работы каждой из них.  
RetinaNet架构的第三部分是分类子网和回归子网。每个子网在输出时分别提供关于对象类别和其在图像中位置的答案。我们来看看每个子网的工作原理。

Разница в принципах работы рассматриваемых блоков подсетей не отличается до последнего слоя. Каждый из них состоит из четырёх слоёв свёрточных сетей. В слое формируются 256 карт признаков. На пятом слое количество карт признаков изменяется. Регрессионная подсеть имеет 4 умножить на A карт признаков, классификационная K умножить на A карт признаков, где A – количество якорных рамок. Подробное описание якорных рамок мы рассмотрим далее, а K – это количество классов объектов. На последнем слое каждая карта признаков преобразуется в набор векторов. Регрессионная модель на выходе имеет для каждой якорной рамки вектор из четырёх значений, указывающих положение целевой рамки относительно якорной. Классификационная модель имеет на выходе для каждой якорной рамки one-hot вектор длиной K, в котором индекс со значением 1 соответствует номеру класса, который сеть присвоила объекту.  
这些子网的工作原理在最后一层之前没有区别。每个子网由四层卷积网络组成。在每层中形成256个特征图。在第五层中，特征图的数量发生变化。回归子网有4乘以A个特征图，分类子网有K乘以A个特征图，其中A是锚框数量，我们将稍后详细讨论，K是对象类别的数量。在最后一层，每个特征图被转换为一个向量集合。回归模型为每个锚框输出一个由四个值组成的向量，指示相对于锚框的位置。分类模型为每个锚框输出一个长度为K的one-hot向量，其中值为1的索引表示网络分配给对象的类别编号。

## Якорные рамки <br>锚框

Якорная рамка (anchor box) – это гиперпараметр нейросетей детекторов, заранее определённый ограничивающий прямоугольник, относительно которого работает сеть. Допустим, сеть имеет на выходе карту признаков размером 3 на 3. В RetinaNet каждая из ячеек имеет 9 якорных рамок, каждая из которых имеет разный размер и соотношение сторон. Во время обучения каждая целевая рамка подбирается в соответствии с якорными рамками. Если их показатель Intersection over Union (IoU) имеет значение выше чем 0,5, то якорная рамка назначается целевой. Если значение меньше 0,4, то оно считается фоном. В других случаях якорная рамка будет проигнорирована при обучении. Классификационная сеть обучается относительно выполненного назначения класса объекта или фона, а регрессионная сеть обучается относительно координат якорной рамки. Важно отметить, что ошибка вычисляется относительно якорной, а не целевой рамки.  
锚框（anchor box）是神经网络检测器的超参数，是一个预定义的限定矩形。假设网络输出一个3x3的特征图。在RetinaNet中，每个单元格有9个锚框，每个锚框有不同的尺寸和比例。在训练过程中，每个目标框与锚框相匹配。如果它们的交并比（Intersection over Union, IoU）超过0.5，则锚框被指定为目标框。如果值小于0.4，则被视为背景。在其他情况下，锚框在训练中被忽略。分类网络根据类别或背景的分配进行训练，回归网络根据锚框的坐标进行训练。需要注意的是，误差是相对于锚框而不是目标框计算的。

## Loss в RetinaNet <br>RetinaNet中的损失函数（Loss）

Loss в RetinaNet являются составными. Их составляют два значения: ошибка регрессии и ошибка классификации. Это довольно стандартный подход, ещё ошибку регрессии называют ошибкой локализации. Данные loss использовались ещё в семействе Faster R-CNN, а нововведением является использование focal loss в качестве loss для классификации объектов. Focal loss позволяет не концентрироваться на элементах выборки, на которых сеть сильно уверена, а стараться научиться лучше разделять не такие очевидные случаи, что на практике зарекомендовало себя как очень полезная идея.  
RetinaNet的损失函数由两部分组成：回归误差和分类误差。这是一个相当标准的方法，回归误差也称为定位误差。这些损失函数早在Faster R-CNN系列中就已使用，创新之处在于引入了用于对象分类的focal loss。Focal loss能让网络不再集中于那些已经分类非常明确的样本，而是努力学习更难区分的样本，这在实践中被证明是非常有用的。

## Оценка качества предсказаний <br>评估预测质量

На данный момент существует огромное количество конструктивных идей для построения комбинированных нейросетевых архитектур. Например, на слайде представлен метод, который использует механизм внимания (attention mechanism) для feature fusion при построении ансамбля. Теперь поговорим о том, как оценивать качество получившихся предсказаний и всего детектора в целом.  
目前，有大量方法可以构建组合神经网络架构。例如，在幻灯片上展示了一种使用注意力机制（attention mechanism）进行特征融合（feature fusion）的方法。现在我们来讨论如何评估预测的质量以及整个检测器的表现。