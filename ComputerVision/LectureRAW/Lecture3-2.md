## [MainPage](../../index.md)/[Computer Vision](../README.md)/[Lecture](../Lecture.md)/3-2 RAW

语音识别：Youtube 转文本
断句与标点：
翻译：

# Глубокие нейросетевые архитектуры для детектирования объектов общего плана <br>用于检测一般物体的深度神经网络架构

после того как мы рассмотрели пример классической модели детектирования объектов виолы джонса перейдем теперь подходом основанным на глубоком обучении 1 рассматриваемый подход полностью соответствует классической и во многом не оптимальной схеме сканирующего окна но с использованием глубокого не раз сетевого классификатора данный метод в своем изначальном виде на сегодняшний момент практически не используются виду не оптимальности однако он положил начало семейства классификаторов которые долгое время оставались недосягаемыми по точности для конкурентов при решении задач многопланового детектирования объектов общего плана также из плюсов можно выделить высокую кастомизируемый данного семейства классификаторов итак 1 рассмотренной нами неру сетевой моделью детектора объектов будет арсенин в основе арсенин она же legend bass ткан валюша 0 дней ролл network лежат следующие идеи нахождение потенциальных объектов на изображении и разбиение их на регионы производится с помощью метода select и все извлечение признаков каждого полученного региона производится с помощью сверточек нейронных сетей василий церовани и обработанных признаков производится с помощью метода опорных векторов которые мы рассматривали в одной из предыдущих лекций уточнения границ регионов производится с помощью линейной регрессии в итоге получается отдельные регионы с объектами и их классами в центре стоят свёрточная нейронные сети которые показывают хорошую точность на примере изображений у такой архитектуры есть очевидные недостатки она требует большого количества времени на обучение select и все является эвристическим алгоритмом который не обучается и не оптимален при вычислении плане времени более того общее время работы у данной архитектуры настолько велико что отсутствует возможность использовать данную модель в реальном времени для исправления недостатков or cnn авторы данной архитектуры выпустили следующую версию данной модели она получила название fast арсенин название говорит само за себя основные силы были положены на оптимизацию производительности в смысле времени исполнения в основе данной архитектуры лежит следующий принцип работы изображения подается на вход сверхточной сети а также обрабатывается с помощью селекции все в итоге получается карта признаков как результат обработки исходного изображения с помощью свёрточная кодировщика а также получается регионы потенциальных объектов как результат работы select и все очень поверх исходного изображения координата регионов потенциальных объектов преобразуются в координаты на карте признаков полученная карта признаков с регионами передается свою region of interest пуленк vr здесь на каждый регион накладывается сетка фиксированного размера затем применяется макс pulling для уменьшения размерности каждого региона сетке таким образом все регионы потенциальных объектов имеют одинаковую фиксированную размерность полученные признаки подаются на вход полна связанному свою который передает результат своей работы двум другим полна связным своём 1 функция активации софт макс определяет вероятность принадлежности объекта определенному классу а второй определяет границы региона данного объекта fast or cnn показывает чуть более высокую точность и большой прирост времени обработки по сравнению с арсен and причиной этого является необходимость точнее отсутствие необходимости подавать все регионы на свёрточная слой но тем ни менее данный метод используют затратной select и все поэтому авторы в дальнейшем сделали еще один шаг и появилась модель foster арсенин пастор арсена приблизилась к возможности широкого промышленного применения путем существенных оптимизации скорости работы рассмотрим подробнее устройство в основу фактор силен был положен новый метод локализации объектов взамен select и все же он получил название арбель регион проползу network в основе рпн лежит свёрточная сеть системой якорей таким образом общий принцип архитектуры foster арсенин выглядит следующим образом изображение подается на вход свёрточная нейронная сеть и кодировщик у так формируется карта признаков карта признаков обрабатывается слоем рпн здесь скользящее окно проходиться по карте признаков центр скользящего окна связан с центром якоря якоре этой области имеющие разные соотношения сторон и разные размеры то есть якорь задает форму и размер окна то есть это некоторая структура которая просто отвечает за форму и размер сканирующего окна авторы используют 3 соотношение сторон и три размера на основе метрики interception aver union степени пересечения якорей истинных размеченных прямоугольников выносится решение о текущем регионе есть объект или нет далее используется алгоритм fast cnn карта признаков с полученными объектами передается свою region of interest с последующей обработкой полна связанными слоями с классификацией а также определением положения объекта модель fast or are cnn справляется немного хуже с локализацией но работает быстрее fast арсен то есть основное и фактически единственное принципиальное отличие fast or are seen and fast арсенин является в замещении алгоритма select и все свёрточная архитектурой рпн которая позволяет немного потеряв в точности с если на повысить скорость работы метода yolo или you only look vans это очень популярная на данный момент семейства архитектур которая используется для распознавания множественных объектов на изображении главная особенность этих архитектур по сравнению с другими состоит в том что большинство систем применяют свёрточная сети несколько раз к различным регионам изображения как например только что рассмотрена и семейства в poster арсен виола же карточные сети применяются один раз ко всему изображению сразу здесь сеть делят изображения на своеобразную сетку и предсказывает балдин боксы и вероятности того что в них присутствует искомый объект для каждого участка плюсы данного подхода состоят в том что сеть смотрит на все изображение сразу и учитывает контекст при детектировании распознавания объектов также yolo примерно в тысячу раз быстрее чем арсенин и примерно 100 раз быстрее чем фактор семен как уже было сказано yolo работает по принципу single shot это означает что архитектура сети устроена таким образом что за один проход кадра на нём детектируется все объекты на слайде представлена архитектура yolo на вход yolo подается 3 канальное изображение у которого меняется размер до 400 48 пикселов в качестве стороны квадрата то есть получается квадратная картинка 448 на 448 пикселов над полученным изображением проводится дальнейшее преобразование первое преобразование заключается в прогоне и изображения через часть модифицированные архитектуры google лет после этого преобразования получаются карты признаков размером 14 на 14 на 1024 элемента далее применяются 2 свертки после второй свертки размерность уменьшается до 7 на 7 на тысячи 24 элемента далее производится еще одна свёртка результат дважды прогоняется через полна связный свой изменяется до размерности 1470 на 1 и в итоге трансформируется в тендер размером 7 на 7 м 30 полученный модель зарок применяется процедура детектирования на выходе которой получается результирующие детектирование тензор представляет собой отображение сетки 7 на 7 на изображении 30 значений несут информацию и ячейки 10 значение для двух возможных рамок 20 значений отношения каждом из 20 доступных классов вся эта информация фильтруется отфильтрованные данные отображаются последующие модификации yolo были сфокусированы на улучшение регрессии bounded боксов а также на добавление 3 медальных подходов для улучшения детектирования объектов в разных масштабах еще одной знаковой one stage архитектурой для детектирования объектов является ssd или семью shot детектор название говорит само за себя в ssd используется наиболее удачные хаки архитектуры эола например на максимум сопряжён и добавляются новые чтобы нейросеть быстрее и точнее работала но и как следствие из названия отличительная особенность данной архитектуры от foster арсенин подходов их подобным здесь также как виола производится детектирование объектов за один прогон с помощью заданные сетки окон на пирамиде изображений пирамиды изображений и закодировано сверточек танцорах при последовательных операциях свертки и буллинга при операции max- pulling пространственная размерностью бывает таким образом определяются как большие так и маленькие объекты за один прогон сети еще одна архитектура и he шин бет состоит из и пишет нет в качестве основы для извлечения признаков мы рассматривали семейства и fishing net наши лекции про классификацию объектов после свёрточная кодировщика на основе их и шепнет работает слой с пирамидой признаков под названием и фпн который производит фьюжен разноуровневых признаков и fish is not кодировщика далее результат передается в стандартную настройку вычисляющую класс и рамку объекта как показано на представленном слайде очень интересное архитектурное решение для реализации детектора объектов предлагают авторы дитя основная суть deuter заключается в том что данный метод сразу предсказывает все объекты и тренируются с боссом которые делает двусторонние соответствия между предсказан ими боксами и разметкой получается что отсутствует потребность в якорях и но максимум со прыщей но есть один минус даже авторы данной архитектуры признают что дитя отлично работает на больших объектах но хуже на мелких более того для тренировки данной архитектуры требуется как указано в оригинальной статье так стволом тренинг стадию а также дополнительные loss причиной этого является тот факт что данная архитектура основана на использовании архитектуры трансформера отметим что то подобное решение все чаще и чаще используется в современном компьютерном зрение но плюсом является то что подобный подход можно использовать фразу для широкого ряда задач например сегментации для прямого предсказания сетов нужны две составные части лосс который делает уникальный matching между предсказан ими и размечен ими боксами и архитектура которая за один проход предсказывает это объектов и моделирует их взаимосвязи модель предсказывает н объектов за один раз то есть некоторое фиксированное число обычно это число значительно выше чем количество реальных объектов которые могут быть представлены на изображении лосс делает двусторонние сопоставления и оптимизирует волосы для боксов в качестве фича экстрактора или backbone можно использовать любую архитектуру но на выходе авторы хотят иметь карты признаков с двумя тысячами 48 каналами причем высота и ширина данных card 32 раза меньше оригинальных encoder эдик ордер инвариантные перестановка рассмотрим encoder начали используется свёртка один-на-один чтобы уменьшить количество каналов до определенного числа поскольку encoder у на вход необходимо подавать последовательности так как мы имеем дело с архитектурой трансформера исходные данные преобразуются чтобы получить размерность gina аж на w где эти w это ширина и высота ади это и есть количество каналов которые нам необходимо венка озере используется мал тих этот экшен причем каждому отель sino добавляется позишн медикс рассмотрим дико dir die кадир декодирует объекты параллельно в каждом слое на вход дополнительно падают и нам виден гав это тренируемые позиции на у encoding которые добавляются на каждом слове им дали название объект клэрис на выходе и викинги независима друг от друга декодируется в координаты боксов и классы благодаря attention у модель может учитывать взаимосвязи между объектами смотрим далее архитектуру точнее ее составляющую которая и производит преобразование промежуточных представлений в тематические осмысленные выходные данные данная голова нейросети представляет собой трехслойный персептрон с помощью него как мы уже говорили предсказываю ца координаты центра боксов их размеры также с помощью активации софт макс возможно предсказывать класс в каждом слое декодера добавляются предсказание параметры которых делится между собой а также применяется венгерские потери ангаре лаз также дополнительно используется в ернар для нормализации входов с каждого слоя декодируем 