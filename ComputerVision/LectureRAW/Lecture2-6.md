## [MainPage](../../index.md)/[Computer Vision](../README.md)/[Lecture](../Lecture.md)/2-6 RAW

语音识别：Youtube 转文本  
断句与标点：chatGPT 4o  
翻译：chatGPT 4o  

# 2.6 Функции потерь и метрики качества <br>损失函数和质量指标

Ранее мы обсудили архитектуры и методы оптимизации градиентного спуска для обучения глубоких нейросетей. Теперь рассмотрим функции потерь (loss), которые мы будем минимизировать в процессе обучения наших архитектур для решения задач классификации.  
我们之前讨论了用于训练深度神经网络的架构和梯度下降优化方法。现在我们来讨论在训练我们的架构以解决分类问题的过程中需要最小化的损失函数（loss）。

Для начала рассмотрим случай двух классов. Самой часто применяемой функцией потерь является в данном случае двоичная кросс-энтропия (binary cross-entropy). Для каждого сэмпла в тестовой выборке производится подсчет суммы произведений метки класса на логарифм предсказания для этой метки. Два слагаемых выполняют роль проверки истинности предсказания метки для каждого класса. В итоге результат суммируется по всем сэмплам тестовой выборки и усредняется.  
首先我们来看二分类的情况。在这种情况下，最常用的损失函数是二元交叉熵（binary cross-entropy）。对于测试集中每个样本，计算类别标签与该标签预测值的对数乘积之和。两个加项分别执行每个类别标签预测值的真值检验。最终，结果在测试集中所有样本上求和并取平均值。

Рассмотрим еще один вариант бинарной функции потерь — hinge loss, которая подразумевает метки класса "1" и "-1", что актуально для активации с помощью гиперболического тангенса, например. Отметим, что для использования в нейросетях предпочтителен сглаженный вариант.  
我们再来看另一个二元损失函数的变种——hinge loss，它假设类别标签为"1"和"-1"，这在使用双曲正切函数（tanh）进行激活时很常见。例如，在神经网络中，优选使用平滑的hinge loss变体。

Теперь поговорим о том, как задать функцию ошибок при выборе одного из нескольких классов. Отметим, что бинарная кросс-энтропия обладает естественным обобщением на случай нескольких классов. Для этого достаточно для каждого сэмпла в тестовой выборке считать сумму по всем классам из слагаемых, стоящих из индикаторов истинной метки (т.е. значения истинного распределения) на логарифм предсказанной вероятности текущего сэмпла для этого класса.  
现在我们讨论在选择多个类别之一时如何设定错误函数。值得注意的是，二元交叉熵在多个类别的情况下有一个自然的扩展。为此，足够对测试集中每个样本计算所有类别的加项之和，这些加项由真值标签（即真实分布的值）与当前样本的该类别预测概率的对数相乘得到。

Заметим, что классификация может происходить с возможностью выбирать сразу несколько классов, например, форму и цвет фруктов. Тогда каждую выходную сеть, соответствующую определенному классу, можно обернуть в sigmoid или другую функцию элементарной активации и считать loss с помощью бинарной кросс-энтропии для каждого выхода.  
需要注意的是，分类可以同时选择多个类别，例如水果的形状和颜色。在这种情况下，可以将对应于特定类别的每个输出网络包装在sigmoid或其他基本激活函数中，并使用二元交叉熵来计算每个输出的loss。

Теперь поговорим о том, как же дать оценку качества полученной модели. Самыми простыми для понимания показателями являются precision и recall. Precision определяется отношением количества верно классифицированных как принадлежащих данному классу элементов к количеству всех элементов тестовой выборки, которые модель классифицировала как элементы данного класса. Recall определяется как отношение количества элементов, верно классифицированных как принадлежащие рассматриваемому классу, к количеству всех элементов тестовой выборки, принадлежащих данному классу.  
现在我们讨论如何评估模型的质量。最简单易懂的指标是精确度（precision）和召回率（recall）。精确度定义为正确分类为某一类别的元素数与模型分类为该类别的所有元素数的比值。召回率定义为正确分类为该类别的元素数与测试集中所有真实属于该类别的元素数的比值。

Для множества классов можно усреднить значения, полученные для каждого класса индивидуально. F-мера позволяет одновременно оценивать precision и recall с помощью одного численного показателя. Параметр β отвечает за приоритет между precision и recall. Он принимает значения в диапазоне от нуля до единицы в случае, когда стоит задача отдать приоритет точности, и больше единицы — когда в приоритете находится полнота. В случае, когда β равно единице, получается сбалансированная F-мера, её также называют F1-мерой. F-мера также может усредняться между несколькими классами.  
对于多个类别，可以对每个类别的结果进行平均。F值（F-measure）能够同时评估精确度和召回率，并用一个数值表示。参数β决定了精确度和召回率之间的优先级。当β取值在0到1之间时，优先考虑精确度；当β大于1时，优先考虑召回率。当β等于1时，得到的是平衡的F值，称为F1值。F值也可以在多个类别间进行平均。

Еще одной популярной мерой качества бинарного классификатора является ROC-кривая (receiver operating characteristic). Данная характеристика показывает, как возрастает количество верно классифицированных объектов с ростом тестовой выборки. Особенностью ROC-кривой является её инвариантность относительно отношения цены ошибки первого и второго рода. Чтобы нарисовать ROC-кривую, предварительно нужно сгруппировать все элементы тестовой выборки по результатам классификации: сначала принадлежащие заранее выбранному классу, затем не принадлежащие. После этого надо взять единичный квадрат на координатной плоскости и разбить его на m равных частей горизонтальными линиями и на n вертикальными, где m — число единиц среди правильных меток класса на тестовом множестве, n — число нулей. В результате квадрат разбивается сеткой m на n.  
另一个常用的二分类质量评估指标是ROC曲线（接收者操作特性曲线）。该曲线展示了随着测试集规模的增加，正确分类的对象数量的变化。ROC曲线的一个特点是它对于第一类和第二类错误代价的比值是不变的。要绘制ROC曲线，首先需要根据分类结果对测试集中的所有元素进行分组：先是属于预定类别的，然后是不属于的。之后，在坐标平面上取一个单位正方形，并将其水平分成m等份，垂直分成n等份，其中m是测试集中正确标签为1的数量，n是0的数量。结果是正方形被分成m×n的网格。

Далее последовательно просматриваются упорядоченные значения модели на тестовой выборке и прорисовываются на сетке линии, переходя из одного узла в другой, начиная с начала координат. Если значение метки класса в просматриваемой строке равно единице (имеется в виду строка с упорядоченными результатами классификации на тестовой выборке), то делаем шаг вверх; если ноль, то шаг вправо. Ясно, что в итоге мы попадем в точку (1, 1), так как сделаем в сумме m шагов вверх и n вправо. В итоге значения нашей метрики, близкие к единице, свидетельствуют о том, что классификатор удался; близкие к нулю значения свидетельствуют о том, что классификатор угадывает класс с точностью до наоборот; значения, близкие к 0,5, говорят о том, что классификатор выдает значения, близкие к случайным.  
然后按顺序查看模型在测试集上的分类结果，并在网格上绘制线条，从一个节点移到另一个节点，起点是原点。如果当前行的类别标签值为1（即测试集中分类结果的顺序行），则向上移动一步；如果为0，则向右移动一步。显然，最终我们会到达点(1, 1)，因为总共向上移动了m步，向右移动了n步。最终，如果我们的指标值接近1，说明分类器表现良好；接近0说明分类器的分类结果与真值完全相反；接近0.5说明分类器的结果接近随机。

В принципе, ROC-кривая может быть вычислена для любой выборки, однако кривая, вычисленная по обучающей выборке, является оптимистично смещенной влево и вверх вследствие переобучения. Величину этого смещения предсказать довольно трудно, поэтому на практике данную кривую всегда оценивают по независимой тестовой выборке.  
原则上，ROC曲线可以用于任何数据集，但是用训练集计算的ROC曲线通常是乐观的左偏和上偏，这是由于过拟合导致的。预测这种偏移量相当困难，因此在实际操作中，通常使用独立的测试集来评估该曲线。

На этом лекция подошла к концу. Спасибо за внимание!  
本次讲座到此结束。谢谢大家的关注！
